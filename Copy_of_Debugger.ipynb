{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Bb2hhamnI6MecpSPZXvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedinaimoke/ai_codecrafters/blob/code_debugger/Copy_of_Debugger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6nQjKAOQA5L",
        "outputId": "6e6e5bcb-7b89-4a27-bb2b-d59faff54b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.0-py3-none-any.whl (220 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/220.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/220.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install openai==0.28"
      ],
      "metadata": {
        "id": "xqckO81CWCX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "T-0kx7imjwhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "kuksdAtegNon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "p-Btpf5LIolO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_python_code(code):\n",
        "    try:\n",
        "        # Input validation - You may want to add more specific validation logic\n",
        "        output = subprocess.check_output([\"python3\", \"-c\", code], stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "        # Provide clear feedback to the user\n",
        "        return True, output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Provide clear feedback to the user\n",
        "        return False, e.output\n",
        "    except Exception as e:\n",
        "        # Provide clear feedback to the user\n",
        "        return False, str(e)"
      ],
      "metadata": {
        "id": "EzqGHEoHMBzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo:my-org:custom_suffix:id\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "f5nquJL2qAnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fix_python_code(code, error_output):\n",
        "    prompt = (\n",
        "        \"Here is Python code and an error message in Terminal:\\n\\n\"\n",
        "        f\"{code}\\n\\n{error_output}\\n\\nPlease fix the code.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            engine=\"text-davinci-002\",  # You can choose the engine that supports completions\n",
        "            prompt=prompt,\n",
        "            max_tokens=150,\n",
        "            n=1,\n",
        "        )\n",
        "\n",
        "        if 'choices' in response and response['choices']:\n",
        "            return response['choices'][0]['text']\n",
        "        else:\n",
        "            return \"Unable to get a valid response from the model.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "6A-je_PDYVW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_debug_python():\n",
        "    max_attempts = 5\n",
        "\n",
        "    # Accept Python code snippet as user input\n",
        "    code = input(\"Enter Python code:\\n\")\n",
        "\n",
        "    for attempt in range(1, max_attempts + 1):\n",
        "        success, output = run_python_code(code)\n",
        "\n",
        "        if success:\n",
        "            print(\"The Python script ran successfully!\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"Attempt {attempt}: Error encountered while running the script:\")\n",
        "            print(output)\n",
        "\n",
        "            fixed_code = fix_python_code(code, output)\n",
        "            print(f\"GPT-3.5 turbo suggested fix:\\n{fixed_code}\\n\")\n",
        "\n",
        "            # Uncomment the following lines if you want to apply the suggested fix\n",
        "            # code = fixed_code\n",
        "\n",
        "    if not success:\n",
        "        print(\"Maximum number of attempts reached. Please try fixing the script manually or run AutoDebug again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    auto_debug_python()"
      ],
      "metadata": {
        "id": "XziMaxIFYdmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdTvJd9ujylt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}